{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Aim:` *Notebook for the purpose of Climate Risk Assessment lecture:* `Xarray, Numpy and Error Handling`\n",
    "\n",
    "`Author:` Mubashshir Ali with additions by Martin Aregger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION: For this notebook to work you need the two files:**\n",
    "- \"pr_EUR-11_ICHEC-EC-EARTH_rcp85_r12i1p1_CLMcom-CCLM4-8-17_v1_day_20210101-20211231_LL.nc\"\n",
    "- \"TREFHT_EU_10-members_19701999_20702099.nc\"\n",
    "\n",
    "You can download them from ILIAS!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Numpy and why do we need it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` is considered the \"fundamental package for scientific computing in Python\". It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything we do today is also possible without Numpy, it would just be more time consuming and significantly more difficult! Additonally, the code in numpy has been optimized by the community and it is very efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # This is the conventional way of importing Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lecture we looked at different basic datatypes. You may have noticed that we did not have a \"multidimensional\" datatype. Only Lists, Tuples, Sets and Dictionaries. If we want to store multidimensional data with the base python we have to put lists into lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = [0, 1, 2, 3, 4]  # This is a 1-dimensional array\n",
    "b = [7, 8, 0, 1, 3]\n",
    "\n",
    "c = [a, b]  # This is a 2-dimensional array\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well if you are doing simple calculations in a low dimensional space. However, if you want to go into higher dimensions and do complex matrix computations it becomes impractical quickly. That is where Numpy has its strengths. It implements ndarrays (among many other useful things). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display  # This is a convenient packagae which allows us to show websites within a jupyter notebook\n",
    "\n",
    "display.Image(\n",
    "    url=\"https://fgnt.github.io/python_crashkurs_doc/_images/numpy_array_t.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we look at 4 different ways to initialize numpy arrays:\n",
    "- From arbitrary dimensions\n",
    "- From Lists\n",
    "- Subsequent numbers\n",
    "- Subsequent numbers with a given step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize an array of arbitrary dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(shape=(4,))  # a 1-dimensional array filled with ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(shape=(2, 3))  # two rows, three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((4, 3, 2))  # 4 by 3 by 2 array filled with random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(2, 10, size=(2, 4, 3, 2))  # random integers from 2 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "harder to visualize? think that the $4^{th}$ dimension is time. So we have two 3D blocks like the in the figure above at two different time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to create a numpy array of the above list a just call np.array(a)\n",
    "b = np.array(a)\n",
    "## or directly give the list into numpy array function\n",
    "c = np.array([1, 2, 3, 4, 5, 6])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Subsequent numbers with a given step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 10\n",
    "step = 2.5\n",
    "\n",
    "np.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Subsequent n numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful way to create an array is when we want a given amount of number between a given range\n",
    "\n",
    "Example: if we need 50 numbers between 0-10 with equal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 10\n",
    "n = 50\n",
    "\n",
    "np.linspace(start, end, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In programming, an attribute is a piece of information that is associated with an object. In the context of arrays, array attributes are pieces of information that describe the properties of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random(\n",
    "    (4, 3, 2)\n",
    ")  # Creating an example array filled with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.ndim  # number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape  # number of elements in each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.size  # overall size, i.e. total number of elements (just the product of the amount of elements in each dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.dtype  # types of array elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If elements are of different type (e.g. you have got intengers and strings), you need to be careful when performing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([1.0, 2, 3, 4.0, 5, \"c\"])\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0] + c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple different datatypes are within an array at initialization, Numpy will try to find a datatype which can \"fit\" all of them. Here it interprets the numbers as characters because only then the 'c' character can be stored. Datatypes can not be mixed within the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slicing and indexing of arrays works the same as with lists. However, here we may deal with multiple dimensions. To slice the multiple dimensions you simply add the commands for each dimension separated by commas. array[dim1,dim2,dim3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random((4))  # 1D example array\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a 1D array it's just like with a list:\n",
    "print(arr[2])\n",
    "print(arr[1:3])\n",
    "print(arr[:2])\n",
    "print(arr[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random((4, 2))  # 2D array\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just specify what elements to pick along each dimension. In 2D, just read it as: array[rows, columns]\n",
    "<br>\n",
    "If you want to take all elements of the first two rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0:2, :]  # remember, index starts at 0 and slicing will give you all elements within the slice, not the last index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, omitting rows is not allowed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher-dimensional arrays follow the same principle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random((4, 2, 5))  # 2D array\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[-1, :, 2:4]  # last \"block\" (-1), all rows (:) in the third and fourth columns (2:4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very important.** Whenever in python you have a variable *a* and you do something like:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a=b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what you might think you are doing is that you create a variable called *b* with the same value of the varaible *a*. However, what you are actually doing is creating a variable *b* which is identitical to *a*. So if you change *b* you also change *a*. Not being aware of this can easily mess up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = a\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[2] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless the above is in fact intended, what you might instead do is assigning to *b* a *copy* of *a*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = a.copy()  # assign a copy\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[2] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily reshape arrays (i.e. from 2D to 1D), as along as you preserve the size, i.e. the total number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random((4, 2))  # 2D array\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.reshape(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.reshape(2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 5, 3], [4, 2, 6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.max()  # overall max - same with min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The axis keyword can be used to apply a function only along a particular axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.max(axis=0)  # column-wise max - same with min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.max(axis=1)  # row-wise max - same with min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()  # overall sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=0)  # column-wise sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=1)  # row-wise sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean()  # overall sum - and you can also get it row-wise or column-wise as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1, 2, 3], [4, 5, 6]]) * 2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(a, b)  # add two arrays element wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.subtract(a, b)  # subtract two arrays element wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "np.multiply(a, b)  # multiply two arrays element wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three above also work between two vectors of different dimensions, as long as one dimension is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[0])\n",
    "print(b)\n",
    "np.multiply(a[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(a[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.subtract(b, a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. and what about the cross-product? Use a .dot(). Here the order matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.dot(a[0])  # b(2,3) X a[0](3,1) vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer, numpy also implements these using the usual operators ($+$, $-$, $*$, $/$)\n",
    "and dot / matrix product uses $@$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a * b)\n",
    "print(a / b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to trying to operate two arrays of different shapes, you sometimes need to sort out the so called \"broadcasting\" yourself.\n",
    "\n",
    "This is an advanced topic that you can safely ignore, but you may find details [here](https://numpy.org/doc/stable/user/basics.broadcasting.html) and the following cell.\n",
    "\n",
    "Shape (3,) with shape (2, 3) works, but shape (2,) with shape (2, 3) doesn't unless you explain to numpy which axis of $a$ goes with which of $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([4, 2])\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]]) * 2\n",
    "print(a.shape, b.shape)\n",
    "# print(a * b) # this will not work\n",
    "print(a[:, None].shape)\n",
    "print(a[:, None] * b) # this will, because a[:, None] has the same amount of dimensions as b, so they can be safely broadcast against one another\n",
    "# This is very useful in many cases, one example is standardization along axis 1, I use this a lot\n",
    "print(b_standard := (b - b.mean(axis=1)[:, None]) / b.std(axis=1)[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more advanced: `np.tensordot` gives you complete control for dot products between tensors of any shape, as long as the axes you multiply together are compatible\n",
    "\n",
    "and `np.einsum` is the same with a different way to specify axes if you're into Einstein notation for tensor dot products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.tensordot(a, b, axes=(0, 0)))\n",
    "print(np.einsum(\"i,ij->j\", a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally broadcasting allows you to quickly do *outer* operations. For example from two arrays\n",
    "\n",
    "`a = [1, 2, 3]`, \n",
    "`b = [4, 5, 6]`\n",
    "\n",
    "I want all the differences between all the elements of b and all elements of a (to compute pairwise distances for example)\n",
    "\n",
    "The easiest way to do it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "print(b[:, None] - a[None, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find element in array and array concatenation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice function is where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a == 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it gives back the positions at which the array meets the specified condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1, 2]  # remember counting starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a != 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is needed to concatenate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((a, b))  # stack two arrays vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy arrays are very useful for any calculations you might want to do with data in a gridded format. However, especially with climate model data you usually have not only the data but also attributes on top of it such as coordinates. It gets even more complicated if you have more than one variable for each coordinate. You could just put the additional attributes into a new dimension of your numpy array but there is a more convenient way.  We will use a python library called `xarray` which is specifically designed to make our life easier when handling multi-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the libary as an alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:58:47.542513Z",
     "start_time": "2020-02-17T14:58:47.106263Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr  # xr is, like np for numpy, considered a \"standard\" alias\n",
    "\n",
    "# library to work with climate model data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:58:50.084785Z",
     "start_time": "2020-02-17T14:58:50.074595Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"http://xarray.pydata.org/en/stable/_images/dataset-diagram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climate data is usually stored in the `NetCDF` format. We can use `Xarray` to easily open such a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T15:02:37.864711Z",
     "start_time": "2020-02-17T15:02:37.857912Z"
    }
   },
   "outputs": [],
   "source": [
    "# file to be plotted\n",
    "# Adapt it as per your need\n",
    "# The file can be downloaded from ilias!\n",
    "\n",
    "file1 = \"C:/your/path/TREFHT_EU_10-members_19701999_20702099.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T15:02:38.961080Z",
     "start_time": "2020-02-17T15:02:38.078586Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets load the data by using open_dataset function of xarray\n",
    "\n",
    "ds1 = xr.open_dataset(file1)\n",
    "ds1  # Jupyter allows for a nice formating of the xarray.Dataset in the output. Click through the different parts of the output and try to understand what they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------\n",
    "Here, you can see one of the reasons why `NetCDF` format is used. It presevers the metadata like standard name, units etc.\n",
    "\n",
    "What are the dimensions of the tas variable? \n",
    "\n",
    "`Note:` If your data file has only one variable then one can also use `xr.open_datarray()` to open the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataArray/Data variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Array is the actual data which the dataset holds. It can be a N-D numpy array. A dataset can hold multiple data variables. \n",
    "\n",
    "We see that this dataset has variables called `time_bnds` and `tas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every `DataArray` contains:\n",
    "    \n",
    "* `dimensions`: Eg, lat, lon, time\n",
    "* `coordinates`: labels of each point in the form of a Python-dictionary\n",
    "* `attributes`: Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between dimensions and coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates are labels to your dimensions. This will be more clear when we look at selecting data examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataArray properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the properties of a variable, you have to specifically select it. Here we look at TREFHT (Reference height temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Ways of Selecting Data\n",
    "\n",
    "Basic positional based indexing same as in numpy works, but one has to know the specific position to extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT[0, 1, 1,0]  # gives the time=0, lat=1, lon=1, member=0 position respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:57:56.058360Z",
     "start_time": "2019-06-21T13:57:56.023242Z"
    }
   },
   "outputs": [],
   "source": [
    "# index style selecting\n",
    "ds1.TREFHT.isel(time=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n",
    "Another easy way to select the data by specifying the date as a string using `sel` method. This is label based selection which is possible thanks to `coordinates` in our data. It works on the principle of python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:57:56.120937Z",
     "start_time": "2019-06-21T13:57:56.061125Z"
    }
   },
   "outputs": [],
   "source": [
    "ds1.TREFHT.sel(time=\"1970-01-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:57:56.137173Z",
     "start_time": "2019-06-21T13:57:56.123811Z"
    }
   },
   "outputs": [],
   "source": [
    "# assigning a variable name to our data for easy access\n",
    "data_to_plot = ds1.TREFHT.sel(time=\"1970-01-03\",member_id=\"r1i1251p1f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:57:57.156634Z",
     "start_time": "2019-06-21T13:57:56.142132Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting it in just one line\n",
    "data_to_plot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **we see how xarray makes our life so much easier for quick analysis.** We didn't have to specify a map or axis. It does everything intelligently in the background for us. This saves a lot of time for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one of the many powerful features which xarray offers.\n",
    "\n",
    "**You can also do everything above in just one line using Python's powerful Object-oriented language features** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:57:58.123620Z",
     "start_time": "2019-06-21T13:57:57.161781Z"
    }
   },
   "outputs": [],
   "source": [
    "# selecting and plotting the data in one line\n",
    "ds1.TREFHT.sel(time=\"1970-01-03\",member_id=\"r1i1251p1f1\").plot();\n",
    "# add semicolon to suppress text output, depends on individual taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:58:14.695178Z",
     "start_time": "2019-06-21T13:58:06.805297Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# selecting lat, lon values\n",
    "# quick time series plot for Bern for each member\n",
    "ds1.TREFHT.sel(member_id=\"r1i1251p1f1\").sel(lat=46.9, lon=7.4, method=\"nearest\").plot()\n",
    "# you can see that we have data from 2 different time periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:57:58.151775Z",
     "start_time": "2019-06-21T13:57:58.126576Z"
    }
   },
   "outputs": [],
   "source": [
    "## first we select data to plot\n",
    "## we can select multiple time-steps using slice function\n",
    "temp = ds1.TREFHT.sel(member_id=\"r1i1251p1f1\",time=slice(\"2071-05-15\", \"2071-05-18\"))\n",
    "temp  # print preview of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Since, we have 4 time steps, we can plot it in a _2x2_ fashion__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T13:58:01.710255Z",
     "start_time": "2019-06-21T13:57:58.154578Z"
    }
   },
   "outputs": [],
   "source": [
    "temp.plot(col=\"time\", col_wrap=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling-basic numpy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray is built on top of numpy and is designed to work seamlessly with numpy arrays. You can used numpy functions on xarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying along a specific dimension\n",
    "ds1.TREFHT.min(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.min(dim=\"time\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying values inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we might want to change values within a xr.DataSet. We can do this \"inplace\" which means we are changing the values in the same object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing into deg Celsius\n",
    "ds1.TREFHT.values = ds1.TREFHT.values - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when modifying data like that because the metadata says temperature is in Kelvin. So let's correct the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.attrs[\"units\"] = \"degC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again\n",
    "ds1.TREFHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid confusion save it as a separate variable when you modify things inplace\n",
    "\n",
    "trefht_in_degC = ds1.TREFHT - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the new variable is just an xarray dataarray\n",
    "type(trefht_in_degC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving file to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your `data_to_plot` file, it is better to save the file to disk especially if the calculations to produce the file took a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"/your/directory/data_to_plot.nc\"  # change it to your directory\n",
    "data_to_plot.to_netcdf(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter a new topic: Errors. You've probably seen a couple of errors by now. Below there are a couple of typical examples.\n",
    "To deal with Errors:\n",
    "\n",
    "* Carefully read the stack trace! It usually tells you exactly where the error happend and what the problem is.\n",
    "* Asking Google for help\n",
    "* Looking up on stackoverflow for FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds  # The object we are trying to call does not exist. -> We never initialized ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT.sel(\n",
    "    time=\"2000-01-01\"\n",
    ")  # The 2000-01-01 is not in the dataset (Not in the available times in the time coordinate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\n",
    "    \"cat\"\n",
    ")  # \"cat\" is not a valid value for the int() function. The function can not convert a string to an Integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.tas()  # Here we make a mistake by trying to call tas() instead of tas. Python interprets tas() as a function of the object ds1. This function does not exist because tas is a variable of ds1 not a function, so a Type Error is caused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.TREFHT[0, 2, 22345]  # we accidentally called a non existing index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing and deleting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In xarray, closing a dataset means releasing any resources associated with it, such as file handles or network connections, and freeing up memory that was used to store the data in the dataset.\n",
    "\n",
    "Closing a dataset is important because it ensures that any resources used by the dataset are properly released, which can help prevent memory leaks or other issues that can arise when working with large datasets. If you do not close a dataset after you are done using it, the resources associated with the dataset may remain open or in use, which can cause problems with subsequent data operations.\n",
    "\n",
    "In addition, closing a dataset can also improve performance by freeing up memory that was used to store the data in the dataset. This can be especially important when working with large datasets that may exceed the available memory on your system.\n",
    "\n",
    "**So please, always close your datasets!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.close()  # here we properly close the dataset. It will still be in memory though.\n",
    "del ds1  # To also release the memory used by the dataset -> delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given the output of a climate model in the form of a csv file. The the data is supposed to contain 3 days of daily precipitation data for a 10*10 pixel area over Bern. First we read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how you can read a csv file\n",
    "import csv\n",
    "\n",
    "input_list = []\n",
    "with open(\"/your/path/ex2_data.csv\", newline=\"\") as file:\n",
    "    reader = csv.reader(file, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        input_list.append(row)\n",
    "\n",
    "input_list = [\n",
    "    element[0] for element in input_list\n",
    "]  # The csv reader gives us a list of strings which we convert to floats here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model data in the form of a one-dimensional list which is rather inconvenient. It would be easier to interpret if we had it in the form of a 3d-array. Can you create an appropriate array from the list? (Hint: the data is ordered with the values of each row appended and then the values of each day appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a nice 3d-array lets look at the data. First let's check what datatype the values have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do any calculations this datatype will not work. Can you convert it into a more useful one? (Hint: we'd like to have a \"float64\" datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have numeric values let's see what the maximum measured precipitation was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this value looks a bit weird for precipitation. The unit is actually $kg*m^{-2}*s^{-1}$ averaged for the whole day. Let's convert the data into a more easily interpretable unit. Can you calculate the number of $mm*m^{-2}$ which fell for each pixel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the maximum value again. Can you figure out on which day the highest precipitation sum was measured? (Hint: look at the \"where\" function in numpy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the daily maxima are interesting, we are actually even more interested in the 3 day precipitation mean for that pixel. Can you calculate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally, can you figure out the total precipitation (in $m^3$) which fell in this pixel and all it's adjacent pixels over the 3 days? Let's assume that each pixel has an area of 1 $km^2$.\n",
    "\n",
    "(Hint: Since the pixel is at the edge (as we can see in the previous exercise) of our $10*10$ grid we should select a $2*3$ area for all 3 days.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now playing around with this small model output was fun but we'd like to look at a bit more data. You can find the full model output in this NetCDF file: 'pr_EUR-11_ICHEC-EC-EARTH_rcp85_r12i1p1_CLMcom-CCLM4-8-17_v1_day_20210101-20211231_LL.nc' (on ilias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you figure out what the dataset contains? Which timeframe do we have? When was it created? What's the title of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the units are in $kg*m^{-2}*s^{-1}$. Can you convert the dataset to total daily $mm*m^{-2}$ and also adapt its metadata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can you find on what day the Bern had the maximum precipitation accumulation? (Bern is located at 46.9480° N, 7.4474° E) (Hint:You may need to google for the correct function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the precipitation looked over switzerland on that day. Can you plot it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you also add the previous and the following day to your plot? Can you arrange them vertically, each plot above another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up: can you properly close the dataset and delete all the xarray objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cra_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
